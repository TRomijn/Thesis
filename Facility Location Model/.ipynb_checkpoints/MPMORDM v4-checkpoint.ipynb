{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versions:\n",
    "* v1: one full cycle. Not yet multiple cycles implemented\n",
    "* v2: MORDM cycle into IO-function\n",
    "    * Can be used for MORDM validation\n",
    "* v3: restructure into MORDM function\n",
    "* v4: mpmordm iterative way\n",
    "\n",
    "TODO inputdata: \n",
    "* FL not random generation\n",
    "* distances based on OSRM route matrix\n",
    "\n",
    "TODO model:\n",
    "* Check values for disruption 1-2 of 0-1\n",
    "\n",
    "TODO:\n",
    "* #Filter out those where no new demand is covered<br>\n",
    "    #TODO: Works only first time. After that doesn't work.<br>\n",
    "    #TODO: Change to \"not more than previous round\"\n",
    "* XX done via saving: return information about objective prioritisation for each returned nondom policy and nondom robust policy\n",
    "* better names inputvariables\n",
    "* change info based on locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ideaMordm(options, split_into = 2, max_depth = 2):\n",
    "    for option in options:\n",
    "        if len(option) == max_depth:\n",
    "            print(\"max depth reached\", option)\n",
    "        else:\n",
    "            for n in range(split_into):\n",
    "                new_option = [option + [n], option + [n]]\n",
    "                print(new_option)\n",
    "                ideaMordm(new_option,split_into,max_depth)\n",
    "    global a\n",
    "    a = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [0, 0]]\n",
      "max depth reached [0, 0]\n",
      "max depth reached [0, 0]\n",
      "[[0, 1], [0, 1]]\n",
      "max depth reached [0, 1]\n",
      "max depth reached [0, 1]\n"
     ]
    }
   ],
   "source": [
    "ideaMordm([[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative (better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 n0\n",
      "__end_period: 0\n",
      "1 n0p0n1\n",
      "1 n0n2\n",
      "__end_period: 1\n",
      "2 n0p0n1p1n3\n",
      "2 n0p0n1n4\n",
      "2 n0n2p1n5\n",
      "2 n0n2n6\n",
      "__end_period: 2\n"
     ]
    }
   ],
   "source": [
    "periods = 3\n",
    "nodes = {\"p{}\".format(p): [] if p !=0 else [\"n{}\".format(p)] for p in range(periods)}\n",
    "\n",
    "node_counter = 0\n",
    "\n",
    "for p in range(periods):\n",
    "    for ni, n in enumerate(nodes[\"p{}\".format(p)]):\n",
    "        print(p,n)\n",
    "        if p+2 <= periods:\n",
    "            # in func\n",
    "            node_counter +=1\n",
    "            nodes[\"p{}\".format(p+1)].append(n+\"p{}n{}\".format(p,node_counter))\n",
    "            #\n",
    "            node_counter +=1\n",
    "            nodes[\"p{}\".format(p+1)].append(n+\"n{}\".format(node_counter))\n",
    "\n",
    "    print(\"__end_period:\",p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(periods):\n",
    "    all_nodes.append(nodes[\"p{}\".format(p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "4\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "for p in all_nodes:\n",
    "    print(len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Standard imports & printing versions\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Own Model import\n",
    "from lib.fl_model_v5 import *\n",
    "# import lib.fl_model_v5 as flm\n",
    "\n",
    "# for natural sorting\n",
    "import re\n",
    "\n",
    "#for nondominated sorting\n",
    "import lib.pareto as pareto\n",
    "from lib.list_imports import find_loaded_modules\n",
    "\n",
    "# for parallel plotting\n",
    "from lib.parallel_plotting import plot_optimal\n",
    "\n",
    "# For checking ema running time\n",
    "import time\n",
    "\n",
    "import ema_workbench as ema\n",
    "from ema_workbench.em_framework import (Policy, IntegerParameter, Constant,\n",
    "                                        RealParameter, ScalarOutcome,\n",
    "                                        perform_experiments, Model)\n",
    "from ema_workbench import ema_logging\n",
    "# from ema_workbench.em_framework.\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load https://gist.github.com/TRomijn/d9d28ba7b7d5eeac1deea5a26dd326b2/raw/loaded_modules.py\n",
    "\n",
    "'''\n",
    "original author: kinverarity1\n",
    "\n",
    "List loaded modules and packages, and show their version numbers\n",
    "and/or Git repository's HEAD commit SHA.\n",
    "\n",
    "\n",
    "Changes:\n",
    "Minor changes to make compatible with Python 3\n",
    "'''\n",
    "# Standard library modules\n",
    "import types\n",
    "import os\n",
    "\n",
    "# Third-party packages\n",
    "import git      # GitPython\n",
    "\n",
    "\n",
    "def module_path(mod):\n",
    "    '''Returns path to the file that module *mod* comes from.\n",
    "    If it doesn't come from a file, return None.'''\n",
    "    if hasattr(mod, '__file__'):\n",
    "        return os.path.abspath(os.path.dirname(mod.__file__))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "def from_git_repo(mod):\n",
    "    '''Does the module *mod* reside in a Git repository?'''\n",
    "    path = module_path(mod)\n",
    "    if path:\n",
    "        try:\n",
    "            repo = git.Repo(path)\n",
    "        except:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def git_path_sha(mod, slice=slice(0, 8, 1)):\n",
    "    '''Return SHA hash for the HEAD commit for the repository\n",
    "    that the module *mod* resides in.'''\n",
    "    repo = git.Repo(module_path(mod))\n",
    "    return repo.git_dir, repo.head.commit.hexsha[:8]\n",
    "\n",
    "\n",
    "def module_version(mod):\n",
    "    '''Return version string for module *mod*, or nothing if\n",
    "    it doesn't have a \"version\" or \"__version__\" attribute.'''\n",
    "    version = []\n",
    "    if hasattr(mod, '__dict__'):\n",
    "        keys = []\n",
    "        for key in mod.__dict__.keys():\n",
    "            if key.lower() == 'version' or key.lower() == '__version__':\n",
    "                v = mod.__dict__[key]\n",
    "                if isinstance(v, str):\n",
    "                    version.append(v)\n",
    "        if keys:\n",
    "            print (mod, keys)\n",
    "    if version:\n",
    "        return ', '.join(version)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "    \n",
    "def find_loaded_modules(only_versioned_modules=True):\n",
    "    '''Return list of loaded modules for which there is a version\n",
    "    number or a Git repository commit SHA.\n",
    "    \n",
    "    Return a list of *(name, version, path_to_git_repo, git_head_sha)*,\n",
    "    which has an HTML property for pretty display in IPython Notebooks.\n",
    "        \n",
    "    '''\n",
    "    def list_of_lists_to_HTML(lists, header_row=None):\n",
    "        '''Convert a list of a list of strings to a HTML table.'''\n",
    "        s = '<table>'\n",
    "        if header_row:\n",
    "            s += '\\n\\t<tr>\\n\\t\\t'\n",
    "            s += ''.join(['<th>%s</th>' % item for item in header_row])\n",
    "            s += '\\n\\t</tr>'\n",
    "        for inner_list in lists:\n",
    "            s += '\\n\\t<tr>\\n\\t\\t'\n",
    "            s += ''.join(['<td>%s</td>' % item for item in inner_list])\n",
    "            s += '\\n\\t</tr>'\n",
    "        s += '\\n</table>'\n",
    "        return s\n",
    "    \n",
    "    class LoadedModules(list):\n",
    "        '''Very simple wrapper for a list of lists of strings, with an attribute\n",
    "        for display in IPython Notebooks.'''\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            list.__init__(self, *args, **kwargs)\n",
    "            \n",
    "        @property\n",
    "        def HTML(self):\n",
    "            from IPython.display import HTML\n",
    "            return HTML(\n",
    "                    list_of_lists_to_HTML(\n",
    "                            self, header_row=['Name', 'Version', 'Path', 'SHA']))\n",
    "                    \n",
    "    objs = LoadedModules()\n",
    "    for i, mod in enumerate(globals().values()):\n",
    "        if isinstance(mod, types.ModuleType):\n",
    "            if hasattr(mod, '__name__'):\n",
    "                name = mod.__name__\n",
    "            else:\n",
    "                name = ''\n",
    "            \n",
    "            if from_git_repo(mod):\n",
    "                path, sha = git_path_sha(mod)\n",
    "            else:\n",
    "                path = ''\n",
    "                sha = ''\n",
    "            \n",
    "            version = module_version(mod)\n",
    "            \n",
    "            if only_versioned_modules:\n",
    "                flag = version or (path and sha)\n",
    "            else:\n",
    "                flag = True\n",
    "            \n",
    "            if flag:\n",
    "                objs.append([mod.__name__, version, path, sha])\n",
    "    objs.sort(key=lambda r: r[0])\n",
    "    return objs\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "\t<tr>\n",
       "\t\t<th>Name</th><th>Version</th><th>Path</th><th>SHA</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>ema_workbench</td><td>1.1.3</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>git</td><td>2.1.9</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>json</td><td>2.0.9</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>lib.pareto</td><td>1.1.1-3</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>numpy</td><td>1.14.2</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>pandas</td><td>0.22.0</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>re</td><td>2.2.1</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>sys</td><td>3.6.4 |Anaconda, Inc.| (default, Mar 12 2018, 20:20:50) [MSC v.1900 64 bit (AMD64)]</td><td></td><td></td>\n",
       "\t</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_loaded_modules().HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is preliminary data. TODO: Find reliable input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Population</th>\n",
       "      <th>Latitude (DD)</th>\n",
       "      <th>Longitude (DD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>743300</td>\n",
       "      <td>27.71</td>\n",
       "      <td>85.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biratnagar</td>\n",
       "      <td>178000</td>\n",
       "      <td>26.46</td>\n",
       "      <td>87.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City  Population  Latitude (DD)  Longitude (DD)\n",
       "0   Kathmandu      743300          27.71           85.31\n",
       "1  Biratnagar      178000          26.46           87.28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DPs from Nepal Data\n",
    "DPs = pd.read_csv(\"Data/Nepal Cities Population.csv\", usecols=[1,2,3,4])\n",
    "\n",
    "# Take only larger cities, because of many null values under 50000 inhabitants. \n",
    "# TODO find better dataset with population and coordinates\n",
    "DPs = DPs [DPs.Population >= 50000]\n",
    "DPs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport</th>\n",
       "      <th>Latitude (DD)</th>\n",
       "      <th>Longitude (DD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tribhuvan intl</td>\n",
       "      <td>27.7</td>\n",
       "      <td>85.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Airport  Latitude (DD)  Longitude (DD)\n",
       "7  Tribhuvan intl           27.7           85.36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create SPs from Nepal Data\n",
    "airports = pd.read_csv(\"Data/Nepal Airports.csv\", usecols=[0,5,6])\n",
    "SPs = airports[airports['Airport'] == \"Tribhuvan intl\"]\n",
    "SPs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FLO0</td>\n",
       "      <td>28.058248</td>\n",
       "      <td>84.283301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLO1</td>\n",
       "      <td>27.236077</td>\n",
       "      <td>80.858178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name        Lat        Lon\n",
       "0  FLO0  28.058248  84.283301\n",
       "1  FLO1  27.236077  80.858178"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random FLs in Nepal\n",
    "long = np.random.uniform(DPs['Longitude (DD)'].min(),\n",
    "                         DPs['Longitude (DD)'].max(), 20)\n",
    "lat = np.random.uniform(DPs['Latitude (DD)'].min(), DPs['Latitude (DD)'].max(),\n",
    "                        20)\n",
    "FLs = pd.DataFrame([lat, long], index=['Lat', 'Lon']).T\n",
    "FLs['Name'] = ['FLO{}'.format(i) for i in range(FLs.shape[0])]\n",
    "FLs = FLs[['Name', 'Lat', 'Lon']]\n",
    "FLs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global: Fixed certain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates\n",
    "# all large cities to demand points\n",
    "DPY = {\"DPY{}\".format(i): y for i,y in enumerate(DPs['Latitude (DD)'])}\n",
    "DPX = {\"DPX{}\".format(i): x for i,x in enumerate(DPs['Longitude (DD)'])}\n",
    "\n",
    "# all international airports to supply points:\n",
    "SPY = {\"SPY{}\".format(i): y for i,y in enumerate(SPs['Latitude (DD)'])}\n",
    "SPX = {\"SPX{}\".format(i): x for i,x in enumerate(SPs['Longitude (DD)'])}\n",
    "\n",
    "# Facility locations\n",
    "FLX = {\"FLX{}\".format(i): x for i,x in enumerate(FLs['Lon'])}\n",
    "FLY = {\"FLY{}\".format(i): y for i,y in enumerate(FLs['Lat'])}\n",
    "\n",
    "# Population demand points\n",
    "DPpop = {\"DPpop{}\".format(i): pop for i,pop in enumerate(DPs['Population'])}\n",
    "# DPpop = {\"DPpop{}\".format(i): random.uniform(10,100) for i in range(nr_of_DPs)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global: Fixed uncertain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_fixed_unc = pd.read_csv(\"Data/uncertainties/fixed_uncertainties.csv\").set_index('var')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Uncertain Data: generate random for now:\n",
    "DFs becomes a global. can be accessed by using its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSR = Disruption\n",
    "DSRDP = {\"DSRDP{}\".format(i): random.uniform (1, 2) for i in range(len(DPX))}\n",
    "DSRFL = {\"DSRFL{}\".format(i): random.uniform (1, 2) for i in range(len(FLX))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label each branch. start with:\n",
    "start_label = \"p0n0\"\n",
    "# Each branch has a separate perception of what the data is.\n",
    "# A dictionary can keep track of data for each branch, linked via label\n",
    "global_dfs_var_unc_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dfs_var_unc_data [start_label] = pd.DataFrame.from_dict({**DSRDP, **DSRFL}, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DSRDP0</th>\n",
       "      <td>1.363024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "DSRDP0  1.363024"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_dfs_var_unc_data [start_label].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>best_estimate</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DSRDP0</th>\n",
       "      <td>1.363024</td>\n",
       "      <td>1.138707</td>\n",
       "      <td>1.699101</td>\n",
       "      <td>1.418904</td>\n",
       "      <td>0.05588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          actual     lower     upper  best_estimate  difference\n",
       "DSRDP0  1.363024  1.138707  1.699101       1.418904     0.05588"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create upper and lower bound\n",
    "global_dfs_var_unc_data[start_label] = global_dfs_var_unc_data[\n",
    "    start_label].rename(columns={0: \"actual\"})\n",
    "global_dfs_var_unc_data[start_label]['lower'] = (\n",
    "    global_dfs_var_unc_data[start_label]['actual'] - 1\n",
    ") * np.random.uniform(size=global_dfs_var_unc_data[start_label].shape[0]) + 1\n",
    "global_dfs_var_unc_data[start_label]['upper'] = (\n",
    "    2 - global_dfs_var_unc_data[start_label]['actual']) * np.random.uniform(\n",
    "        size=global_dfs_var_unc_data[start_label]\n",
    "        .shape[0]) + global_dfs_var_unc_data[start_label]['actual']\n",
    "global_dfs_var_unc_data[start_label]['best_estimate'] = (\n",
    "    global_dfs_var_unc_data[start_label]['upper'] +\n",
    "    global_dfs_var_unc_data[start_label]['lower']) / 2\n",
    "global_dfs_var_unc_data[start_label][\n",
    "    'difference'] = global_dfs_var_unc_data[start_label]['best_estimate'] - global_dfs_var_unc_data[start_label]['actual']\n",
    "global_dfs_var_unc_data[start_label].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['p0n0'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_dfs_var_unc_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Globals:\n",
    "- Create Starting situation policies:\n",
    "- List of all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_policy_tree = {}\n",
    "# # global_models = {}\n",
    "# # global_period_counter = 0 # period is not global\n",
    "# global_node_counter = 0\n",
    "# EMA_model_dict = {}  # XX somewhere else: global\n",
    "# print(\"starting label:\",start_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def create_policies(FL_dict, print_pols=False):\n",
    "    \"\"\"\n",
    "    Takes the current network of Facility Locations and returns all possible policies for one added FL.\n",
    "    \n",
    "    Input: current option (Dict of FLs)\n",
    "    Output: List of options (Dicts of FLs)\n",
    "    \n",
    "    Printing module not completely reliable. doesnt print whats actually in thereTODO\n",
    "    \"\"\"\n",
    "    def natural_key(string_):\n",
    "        return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]\n",
    "    \n",
    "    # All FL names\n",
    "    FL_keys = sorted(FL_dict.keys(),key=natural_key)\n",
    "    # All FL values indicating whether operational\n",
    "    FL_values = [FL_dict[key] for key in FL_keys]\n",
    "    \n",
    "    i_operational_fls = i_FL_op = [i for i,x in enumerate(FL_values) if x == 1]\n",
    "    \n",
    "    # Create list of policies  \n",
    "    pols = np.identity(len(FL_keys))\n",
    "    # Set already operational facilities to operational\n",
    "    pols[:,i_operational_fls] = 1\n",
    "    \n",
    "    #Delete policies where no new FLs are placed \n",
    "    new_n_operational_fls = sum(FL_values) + 1\n",
    "    pols = pols[pols.sum(axis = 1) == new_n_operational_fls]\n",
    "\n",
    "    \n",
    "    # Return a list of dictionaries\n",
    "    policy_list = []\n",
    "    for pol in pols:\n",
    "        policy_list.append({key:value for key,value in zip(FL_keys,pol)})\n",
    "    \n",
    "    if print_pols == True:\n",
    "        print(\"total policies:\",len(policy_list))\n",
    "        for n,i in enumerate(policy_list):\n",
    "            for v in i.values():\n",
    "                print (int(v), end='')\n",
    "            print(\" <- policy {}\".format(n))\n",
    "                \n",
    "    return policy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_signalNoise(data, obj):\n",
    "    '''\n",
    "    data : 1d array, the values of an outcome indicator for a policy\n",
    "    obj  : the objective corresponding to an outcome indicator, 1 or -1\n",
    "    '''\n",
    "    if obj == -1: #MINIMIZE\n",
    "        score = (np.mean(data)+1)*(np.std(data)+1) #to avoid division by zero if the std. deviation is zero, we can add 1.\n",
    "    elif obj == 1: #MAXIMIZE\n",
    "        score = (np.mean(data)+1)/(np.std(data)+1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_maxregret(data, obj):\n",
    "    '''\n",
    "    data : a list of 1d arrays whose shape is no_policies x no_scenarios\n",
    "    obj : -1 or 1, the objective \n",
    "    '''\n",
    "    data = np.array(data)\n",
    "    if obj == 1: #MAXIMIZE \n",
    "        #find the best case in each scenario, therefore use the max function of numpy on the axis of policies\n",
    "        zero_regrets = np.max(data, axis=0)\n",
    "    elif obj == -1: #MINIMIZE\n",
    "        zero_regrets = np.min(data, axis=0)\n",
    "    \n",
    "    #determine the regret values for eaxh policy in each scenario\n",
    "    regrets = [abs(np.subtract(data[p], zero_regrets)) for p in range(data.shape[0])]\n",
    "    \n",
    "    max_regrets = np.max(regrets, axis=1)\n",
    "    \n",
    "    return max_regrets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def MORDM(\n",
    "        current=None,\n",
    "        current_period=None,\n",
    "        trace_label=None,\n",
    "        # fixed_data=None,\n",
    "        # var_data=None,\n",
    "        n_scenarios=100,\n",
    "        additional_info=None,\n",
    "        show_MORDM_graphics=False,\n",
    "        show_model_graphics=False):\n",
    "    \"\"\"\n",
    "    current: indexes of current operational locations\n",
    "    trace_label: label of input node\n",
    "    fixed_data: \n",
    "    var_data: df of variable data for each \n",
    "    max_depth: maximum number of total FLS\n",
    "    \"\"\"\n",
    "    #     if sum(current.values()) >= max_depth:\n",
    "    #         raise NotImplementedError(\n",
    "    #             \"Everything might go right(no error). This function is not well implemented. Change to > instead of >=\"\n",
    "    #         )\n",
    "\n",
    "    if show_MORDM_graphics == True:\n",
    "        raise NotImplementedError(\"\"\"visualisations are not implemented yet. \n",
    "            Not sure yet if impementing graphics in MPMORDM is usefull for every period \"\"\"\n",
    "                                  )\n",
    "\n",
    "    #Start Many Objective Optimisation\n",
    "    #best estimate values\n",
    "    best_estimate_disruptions = {\n",
    "        i: be\n",
    "        for be, i in zip(global_dfs_var_unc_data[trace_label]['best_estimate'],\n",
    "                         global_dfs_var_unc_data[trace_label].index)\n",
    "    }\n",
    "\n",
    "    optional_policies = create_policies(current, print_pols=False)\n",
    "\n",
    "    #evaluate all policies\n",
    "    best_est_results_opt_pols = []\n",
    "    for policy in optional_policies:\n",
    "        best_est_results_opt_pols.append(\n",
    "            FL_model(\n",
    "                unit_opening_costs=global_fixed_unc.loc[\"unit_opening_costs\",\n",
    "                                                        \"best_estimate\"],\n",
    "                unit_transport_cost=global_fixed_unc.loc[\"unit_transport_cost\",\n",
    "                                                         \"best_estimate\"],\n",
    "                FL_operations_cost=global_fixed_unc.loc[\"FL_operations_cost\",\n",
    "                                                        \"best_estimate\"],\n",
    "                graphical_representation=show_model_graphics,\n",
    "                FL_range=global_fixed_unc.loc[\"FL_range\",\n",
    "                                              \"best_estimate\"],  # km? --> m\n",
    "                dist_method=\"great_circle\",\n",
    "                lorry_speed=global_fixed_unc.loc[\n",
    "                    \"lorry_speed\", \"best_estimate\"],  #km/u? --> m/s\n",
    "                # fixed certain\n",
    "                **SPX,\n",
    "                **SPY,\n",
    "                **DPX,\n",
    "                **DPY,\n",
    "                **FLX,\n",
    "                **FLY,\n",
    "                **DPpop,\n",
    "                # specific\n",
    "                **policy,\n",
    "                **best_estimate_disruptions))\n",
    "\n",
    "    # outcome indicators, as internally used by the model\n",
    "    oois = [\n",
    "        'total_costs', 'nr_uncovered_DPs', 'total_uncovered_demand',\n",
    "        'max_distr_time'\n",
    "    ]\n",
    "    # Put outcomes in DF\n",
    "    df_best_est_results_opt_pols = pd.DataFrame(\n",
    "        np.asarray(best_est_results_opt_pols)[:, :4], columns=oois)\n",
    "\n",
    "    #nondominated sorting\n",
    "    nondominated_BE_policy_results = np.array(\n",
    "        pareto.eps_sort(\n",
    "            [list(df_best_est_results_opt_pols.itertuples(index=True))],\n",
    "            [1, 2, 3, 4], [1e-9, 1e-9, 1e-9, 1e-9]))\n",
    "\n",
    "    #Filter out those where new demand is covered\n",
    "    #TODO: Works only first time. After that doesn't work.\n",
    "    #TODO: Change to \"not more than previous round\"\n",
    "    nondominated_BE_policy_results = nondominated_BE_policy_results[\n",
    "        nondominated_BE_policy_results[:, 4] != 0]\n",
    "\n",
    "    #put nondominated policies in array\n",
    "    nondom_i = [int(a[0]) for a in nondominated_BE_policy_results]\n",
    "    nondominated_BE_policies = np.array(optional_policies)[nondom_i]\n",
    "\n",
    "    df_nondom_BE_pols = pd.DataFrame(\n",
    "        nondominated_BE_policy_results, columns=[\"i\"] + oois).set_index(\"i\")\n",
    "    df_nondom_BE_pols.to_csv(\n",
    "        \"results/mpmordm/nondom_BE_pols{}.csv\".format(trace_label))\n",
    "\n",
    "\n",
    "    #End Many Objective Optimisation\n",
    "    #Start Robustness analysis\n",
    "\n",
    "    EMA_model_dict[trace_label] = Model(\"flmodel{}\".format(trace_label),\n",
    "                                        FL_model)\n",
    "\n",
    "    EMA_model_dict[trace_label].locations = [\n",
    "        Constant(\"DPX{}\".format(i), x)\n",
    "        for i, x in zip(DPs.index, DPs['Longitude (DD)'])\n",
    "    ] + [\n",
    "        Constant(\"DPY{}\".format(i), y)\n",
    "        for i, y in zip(DPs.index, DPs['Latitude (DD)'])\n",
    "    ] + [\n",
    "        Constant(\"SPX{}\".format(i), x)\n",
    "        for i, x in zip(SPs.index, SPs['Longitude (DD)'])\n",
    "    ] + [\n",
    "        Constant(\"SPY{}\".format(i), y)\n",
    "        for i, y in zip(SPs.index, SPs['Latitude (DD)'])\n",
    "    ] + [\n",
    "        Constant(\"FLX{}\".format(i), x) for i, x in zip(FLs.index, FLs['Lon'])\n",
    "    ] + [\n",
    "        Constant(\"FLY{}\".format(i), y) for i, y in zip(FLs.index, FLs['Lat'])\n",
    "    ]\n",
    "\n",
    "    # model.locations_uncertain =   [\n",
    "    #     RealParameter(\"FLX{}\".format(i), DPs['Longitude (DD)'].min(), DPs['Longitude (DD)'].max()) for i in range(nr_of_FLs)\n",
    "    # ] + [RealParameter(\"FLY{}\".format(i), DPs['Latitude (DD)'].min(), DPs['Latitude (DD)'].max()) for i in range(nr_of_FLs)]\n",
    "\n",
    "    EMA_model_dict[trace_label].constants = [\n",
    "        Constant('graphical_representation', False),\n",
    "        Constant('dist_method', 'great_circle'),\n",
    "        Constant('Error_Test', 1),  # this doesn't do anything. \n",
    "        #list of other constants\n",
    "        #     Constant\n",
    "    ] + EMA_model_dict[trace_label].locations + [  # population DPs\n",
    "        Constant(\"DPpop{}\".format(i), pop)\n",
    "        for i, pop in zip(DPs.index, DPs['Population'])\n",
    "    ]\n",
    "\n",
    "    # Reachability of Demand Points and Facility Locations can be disrupted\n",
    "    # Disruption also determines demand (disr-1)*pop\n",
    "    EMA_model_dict[trace_label].disruptions = [\n",
    "        RealParameter(i, l, u) for i, l, u in zip(global_dfs_var_unc_data[\n",
    "            trace_label].index, global_dfs_var_unc_data[trace_label][\n",
    "                'lower'], global_dfs_var_unc_data[trace_label]['upper'])\n",
    "    ]\n",
    "\n",
    "    EMA_model_dict[trace_label].uncertainties = [\n",
    "        RealParameter(i, l, u)\n",
    "        for i, l, u in zip(global_fixed_unc.index, global_fixed_unc.lower,\n",
    "                           global_fixed_unc.upper)\n",
    "    ] + EMA_model_dict[trace_label].disruptions  #+ model.locations_uncertain\n",
    "\n",
    "    EMA_model_dict[trace_label].outcomes = [\n",
    "        ScalarOutcome(\"total_costs\", kind=ScalarOutcome.MINIMIZE),\n",
    "        ScalarOutcome(\"nr_uncovered_DPs\", kind=ScalarOutcome.MINIMIZE),\n",
    "        ScalarOutcome(\"total_uncovered_demand\", kind=ScalarOutcome.MINIMIZE),\n",
    "        ScalarOutcome(\n",
    "            \"max_distr_time\",\n",
    "            kind=ScalarOutcome.MINIMIZE,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    if [o.name for o in EMA_model_dict[trace_label].outcomes] != oois:\n",
    "        print(\"Watch out! Oois and model outcome names are not similar!\")\n",
    "\n",
    "    nondominated_BE_policies_EMA = []\n",
    "    for name, pol in zip(nondom_i, nondominated_BE_policies):\n",
    "        nondominated_BE_policies_EMA.append(Policy(\"{}\".format(name), **pol))\n",
    "\n",
    "    time1 = time.time()\n",
    "    all_scen_results_nondom_pols = perform_experiments(\n",
    "        EMA_model_dict[trace_label], n_scenarios, nondominated_BE_policies_EMA)\n",
    "    time2 = time.time()\n",
    "    print(\"Total time:{}\".format(time2 - time1), \"\\n\",\n",
    "          \"time per run = {}\".format(\n",
    "              (time2 - time1) /\n",
    "              (n_scenarios * len(nondominated_BE_policies_EMA))))\n",
    "\n",
    "    ema.save_results(all_scen_results_nondom_pols,\n",
    "                     \"results/mpmordm/{}.tar.gz\".format(trace_label))\n",
    "    experiments, outcomes = all_scen_results_nondom_pols\n",
    "\n",
    "    sigN_results = []\n",
    "\n",
    "    for policy in nondominated_BE_policies_EMA:\n",
    "        #filter the outcome values corresponding to each policy using a logical index\n",
    "        logical_index = experiments['policy'] == policy.name\n",
    "        # If ever something goes wrong here, probably add: int() to policy.name\n",
    "        pol_outcomes = {\n",
    "            key: outcomes[key][logical_index]\n",
    "            for key in outcomes.keys()\n",
    "        }\n",
    "        temp_result = {}\n",
    "        for ooi in EMA_model_dict[trace_label].outcomes:\n",
    "            temp_result[ooi.name] = calculate_signalNoise(\n",
    "                pol_outcomes[ooi.name], ooi.kind)\n",
    "        sigN_results.append(temp_result)\n",
    "\n",
    "    df_sigN = pd.DataFrame(\n",
    "        sigN_results, index=[pol.name for pol in nondominated_BE_policies_EMA])\n",
    "\n",
    "    reg_results = {}\n",
    "    # we need to iterate over the outcomes differently now,\n",
    "    #because the maximum egret calculation requires the outcome values for all policies\n",
    "    for ooi in EMA_model_dict[trace_label].outcomes:\n",
    "        data = []\n",
    "        for policy in nondominated_BE_policies_EMA:\n",
    "            logical_index = experiments['policy'] == policy.name\n",
    "            # If ever something goes wrong here, add int() to policy.name\n",
    "            data.append(outcomes[ooi.name][logical_index])\n",
    "        reg_results[ooi.name] = calculate_maxregret(data, ooi.kind)\n",
    "    df_regret = pd.DataFrame.from_dict(\n",
    "        reg_results,\n",
    "        orient='columns',\n",
    "    )\n",
    "    df_regret.index = [pol.name for pol in nondominated_BE_policies_EMA]\n",
    "\n",
    "    all_robustness_scores = pd.merge(\n",
    "        df_regret,\n",
    "        df_sigN,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        suffixes=(\"_regret\", \"_sigN\"))\n",
    "\n",
    "    robust_nondominated_policies = pareto.eps_sort(\n",
    "        [list(all_robustness_scores.itertuples(index=True))],\n",
    "        [i + 1 for i in range(all_robustness_scores.shape[1])],\n",
    "        [1e-9] * all_robustness_scores.shape[1])\n",
    "\n",
    "    if len(robust_nondominated_policies) == 0:\n",
    "        print(\"something went wrong\")\n",
    "    elif len(robust_nondominated_policies) == 1:\n",
    "        print(\"no branching, only a single nondominated robust location\")\n",
    "        temp_cols = [\"pol_i\"] + list(all_robustness_scores.columns)\n",
    "\n",
    "        df_rob_nondom_pols = pd.DataFrame(\n",
    "            robust_nondominated_policies, columns=temp_cols).set_index(\"pol_i\")\n",
    "    #     print(robust_nondominated_policies)\n",
    "    else:\n",
    "        temp_cols = [\"pol_i\"] + list(all_robustness_scores.columns)\n",
    "        df_rob_nondom_pols = pd.DataFrame(\n",
    "            robust_nondominated_policies, columns=temp_cols).set_index(\"pol_i\")\n",
    "\n",
    "    df_rob_nondom_pols.to_csv(\n",
    "        \"results/mpmordm/nondom_rob_pols{}.csv\".format(trace_label))\n",
    "\n",
    "    rob_nondom_i = [int(i) for i in df_rob_nondom_pols.index]\n",
    "    #     return df_rob_nondom_pols\n",
    "    \n",
    "    return np.array(optional_policies)[rob_nondom_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing single cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: save csv nondom pols + csv rob nondom pols\n",
    "possible: clear op variable space with del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 10 scenarios * 4 policies * 1 model(s) = 40 experiments\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 4 cases completed\n",
      "[MainProcess/INFO] 8 cases completed\n",
      "[MainProcess/INFO] 12 cases completed\n",
      "[MainProcess/INFO] 16 cases completed\n",
      "[MainProcess/INFO] 20 cases completed\n",
      "[MainProcess/INFO] 24 cases completed\n",
      "[MainProcess/INFO] 28 cases completed\n",
      "[MainProcess/INFO] 32 cases completed\n",
      "[MainProcess/INFO] 36 cases completed\n",
      "[MainProcess/INFO] 40 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to C:\\Users\\timro\\Dropbox\\MSc EPA\\0 Master Thesis\\Python Files\\Thesis\\Facility Location Model\\results\\mpmordm\\p0n0.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:1.6586172580718994 \n",
      " time per run = 0.041465431451797485\n"
     ]
    }
   ],
   "source": [
    "test = MORDM(\n",
    "    current=start_situation,n_scenarios=10, trace_label=start_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # for mpmordm\n",
    "# start_situation = {key:0 for key in FLs.Name}\n",
    "# global_policy_tree[start_label] = start_situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['p0n0'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_dfs_var_unc_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now first: label management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_decision_based_uncertainty(current_uncertain_data):\n",
    "    return current_uncertain_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting label: p0n0\n",
      "Do mordm, in period: 0 label: p0n0 policy: {'FLO0': 0, 'FLO1': 0, 'FLO2': 0, 'FLO3': 0, 'FLO4': 0, 'FLO5': 0, 'FLO6': 0, 'FLO7': 0, 'FLO8': 0, 'FLO9': 0, 'FLO10': 0, 'FLO11': 0, 'FLO12': 0, 'FLO13': 0, 'FLO14': 0, 'FLO15': 0, 'FLO16': 0, 'FLO17': 0, 'FLO18': 0, 'FLO19': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 10 scenarios * 4 policies * 1 model(s) = 40 experiments\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 4 cases completed\n",
      "[MainProcess/INFO] 8 cases completed\n",
      "[MainProcess/INFO] 12 cases completed\n",
      "[MainProcess/INFO] 16 cases completed\n",
      "[MainProcess/INFO] 20 cases completed\n",
      "[MainProcess/INFO] 24 cases completed\n",
      "[MainProcess/INFO] 28 cases completed\n",
      "[MainProcess/INFO] 32 cases completed\n",
      "[MainProcess/INFO] 36 cases completed\n",
      "[MainProcess/INFO] 40 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to C:\\Users\\timro\\Dropbox\\MSc EPA\\0 Master Thesis\\Python Files\\Thesis\\Facility Location Model\\results\\mpmordm\\p0n0.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:1.887394666671753 \n",
      " time per run = 0.04718486666679382\n",
      "result:||| p0n0p1n1\n",
      "result:||| p0n0p1n2\n",
      "Do mordm, in period: 1 label: p0n0p1n1 policy: {'FLO0': 0.0, 'FLO1': 0.0, 'FLO2': 0.0, 'FLO3': 1.0, 'FLO4': 0.0, 'FLO5': 0.0, 'FLO6': 0.0, 'FLO7': 0.0, 'FLO8': 0.0, 'FLO9': 0.0, 'FLO10': 0.0, 'FLO11': 0.0, 'FLO12': 0.0, 'FLO13': 0.0, 'FLO14': 0.0, 'FLO15': 0.0, 'FLO16': 0.0, 'FLO17': 0.0, 'FLO18': 0.0, 'FLO19': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 10 scenarios * 4 policies * 1 model(s) = 40 experiments\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 4 cases completed\n",
      "[MainProcess/INFO] 8 cases completed\n",
      "[MainProcess/INFO] 12 cases completed\n",
      "[MainProcess/INFO] 16 cases completed\n",
      "[MainProcess/INFO] 20 cases completed\n",
      "[MainProcess/INFO] 24 cases completed\n",
      "[MainProcess/INFO] 28 cases completed\n",
      "[MainProcess/INFO] 32 cases completed\n",
      "[MainProcess/INFO] 36 cases completed\n",
      "[MainProcess/INFO] 40 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to C:\\Users\\timro\\Dropbox\\MSc EPA\\0 Master Thesis\\Python Files\\Thesis\\Facility Location Model\\results\\mpmordm\\p0n0p1n1.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:1.595156192779541 \n",
      " time per run = 0.039878904819488525\n",
      "result:||| p0n0p1n1p2n3\n",
      "result:||| p0n0p1n1p2n4\n",
      "result:||| p0n0p1n1p2n5\n",
      "result:||| p0n0p1n1p2n6\n",
      "Do mordm, in period: 1 label: p0n0p1n2 policy: {'FLO0': 0.0, 'FLO1': 0.0, 'FLO2': 0.0, 'FLO3': 0.0, 'FLO4': 0.0, 'FLO5': 0.0, 'FLO6': 0.0, 'FLO7': 0.0, 'FLO8': 0.0, 'FLO9': 0.0, 'FLO10': 0.0, 'FLO11': 0.0, 'FLO12': 0.0, 'FLO13': 1.0, 'FLO14': 0.0, 'FLO15': 0.0, 'FLO16': 0.0, 'FLO17': 0.0, 'FLO18': 0.0, 'FLO19': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 10 scenarios * 5 policies * 1 model(s) = 50 experiments\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 5 cases completed\n",
      "[MainProcess/INFO] 10 cases completed\n",
      "[MainProcess/INFO] 15 cases completed\n",
      "[MainProcess/INFO] 20 cases completed\n",
      "[MainProcess/INFO] 25 cases completed\n",
      "[MainProcess/INFO] 30 cases completed\n",
      "[MainProcess/INFO] 35 cases completed\n",
      "[MainProcess/INFO] 40 cases completed\n",
      "[MainProcess/INFO] 45 cases completed\n",
      "[MainProcess/INFO] 50 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to C:\\Users\\timro\\Dropbox\\MSc EPA\\0 Master Thesis\\Python Files\\Thesis\\Facility Location Model\\results\\mpmordm\\p0n0p1n2.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:2.0058581829071045 \n",
      " time per run = 0.04011716365814209\n",
      "result:||| p0n0p1n2p2n7\n",
      "result:||| p0n0p1n2p2n8\n",
      "result:||| p0n0p1n2p2n9\n",
      "result:||| p0n0p1n2p2n10\n"
     ]
    }
   ],
   "source": [
    "periods = 2 # 1 location per period -> locations = periods\n",
    "\n",
    "global_node_counter = 0\n",
    "\n",
    "start_situation = {key:0 for key in FLs.Name}\n",
    "global_policy_tree = {start_label : start_situation}\n",
    "global_label_tree = {\n",
    "    \"p{}\".format(p, global_node_counter): []\n",
    "    if p != 0 else [\"{}\".format(start_label)]\n",
    "    for p in range(periods+1)\n",
    "}\n",
    "\n",
    "EMA_model_dict = {}  # XX somewhere else: global\n",
    "print(\"starting label:\", start_label)\n",
    "\n",
    "\n",
    "for p in range(periods):\n",
    "    for node_i, node in enumerate(list(global_label_tree[\"p{}\".format(p)])):\n",
    "#         print(\"|\", p, node)\n",
    "        if p < periods:\n",
    "            print(\"Do mordm, in period:\", p,\"label:\", node,\"policy:\",global_policy_tree[node])\n",
    "#             new_pols = [\"a\", \"b\", \"c\"]\n",
    "            new_pols = MORDM(current=global_policy_tree[node],n_scenarios=10, trace_label=node)\n",
    "            for new_pol in new_pols:\n",
    "                # Create new label\n",
    "                global_node_counter += 1\n",
    "                new_label = node + \"p{}n{}\".format(p + 1, global_node_counter)\n",
    "                print(\"result:|||\",new_label)\n",
    "                # Create new branch\n",
    "                global_label_tree[\"p{}\".format(p + 1)].append(new_label)\n",
    "                # add new policy\n",
    "                global_policy_tree[new_label] = new_pol\n",
    "                # change information based on policy\n",
    "                #TODO not implemented yet\n",
    "#                 global_dfs_var_unc_data[new_label] = global_dfs_var_unc_data[start_label]\n",
    "                global_dfs_var_unc_data[new_label] = change_decision_based_uncertainty(global_dfs_var_unc_data[node])\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "        else:\n",
    "            print(p,\n",
    "                \"if you see this, sth went wrong.\"\n",
    "            )\n",
    "#     print(\"__end_period:\",p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p0': ['p0n0'],\n",
       " 'p1': ['p0n0p1n1', 'p0n0p1n2'],\n",
       " 'p2': ['p0n0p1n1p2n3',\n",
       "  'p0n0p1n1p2n4',\n",
       "  'p0n0p1n1p2n5',\n",
       "  'p0n0p1n1p2n6',\n",
       "  'p0n0p1n2p2n7',\n",
       "  'p0n0p1n2p2n8',\n",
       "  'p0n0p1n2p2n9',\n",
       "  'p0n0p1n2p2n10']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_label_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p0': ['p0n0'],\n",
       " 'p1': ['p0n0p1n1', 'p0n0p1n2'],\n",
       " 'p2': ['p0n0p1n1p2n3',\n",
       "  'p0n0p1n1p2n4',\n",
       "  'p0n0p1n1p2n5',\n",
       "  'p0n0p1n1p2n6',\n",
       "  'p0n0p1n2p2n7',\n",
       "  'p0n0p1n2p2n8',\n",
       "  'p0n0p1n2p2n9',\n",
       "  'p0n0p1n2p2n10']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_label_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0n0 []\n",
      "p0n0p1n1 ['FLO3']\n",
      "p0n0p1n2 ['FLO13']\n",
      "p0n0p1n1p2n3 ['FLO0', 'FLO3']\n",
      "p0n0p1n1p2n4 ['FLO3', 'FLO11']\n",
      "p0n0p1n1p2n5 ['FLO3', 'FLO13']\n",
      "p0n0p1n1p2n6 ['FLO3', 'FLO19']\n",
      "p0n0p1n2p2n7 ['FLO0', 'FLO13']\n",
      "p0n0p1n2p2n8 ['FLO3', 'FLO13']\n",
      "p0n0p1n2p2n9 ['FLO11', 'FLO13']\n",
      "p0n0p1n2p2n10 ['FLO13', 'FLO19']\n"
     ]
    }
   ],
   "source": [
    "for key in global_policy_tree.keys():\n",
    "    poldict = global_policy_tree[key]\n",
    "    print(key,[key2 for key2 in poldict if poldict[key2]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0n0p1n2 ['FLO13']\n",
      "p0n0p1n2p2n7 ['FLO0', 'FLO13']\n",
      "p0n0p1n2p2n8 ['FLO3', 'FLO13']\n",
      "p0n0p1n2p2n9 ['FLO11', 'FLO13']\n",
      "p0n0p1n2p2n10 ['FLO13', 'FLO19']\n"
     ]
    }
   ],
   "source": [
    "for key in global_policy_tree.keys():\n",
    "    if \"n2\" in key:\n",
    "        poldict = global_policy_tree[key]\n",
    "        print(key,[key2 for key2 in poldict if poldict[key2]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMA_model_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MORDM_cycle(current, last, trace_label, fixed_data, var_data, max_depth = 2, additional_info=None):\n",
    "    \"\"\"\n",
    "    MORDM_cycle with micromodel. Micromodel changes factors/information based on the last decision\n",
    "    \n",
    "    \"\"\"\n",
    "    if trace_label != max_depth:\n",
    "        raise NotImplementedError (\"stop if max depth is reached\")\n",
    "    # micromodel here\n",
    "    #Based on current / last\n",
    "    \n",
    "    \n",
    "    MORDM(current, trace_label, fixed_data, var_data, max_depth = max_depth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
