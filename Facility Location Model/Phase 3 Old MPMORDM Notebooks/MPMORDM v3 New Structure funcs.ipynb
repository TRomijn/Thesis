{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versions:\n",
    "* v1: one full cycle. Not yet multiple cycles implemented\n",
    "* v2: MORDM cycle into IO-function\n",
    "* v3: restructure into MORDM function\n",
    "\n",
    "TODO inputdata: \n",
    "* FL not random generation\n",
    "* distances based on OSRM route matrix\n",
    "\n",
    "TODO model:\n",
    "* Check values for disruption 1-2 of 0-1\n",
    "\n",
    "TODO:\n",
    "* #Filter out those where new demand is covered<br>\n",
    "    #TODO: Works only first time. After that doesn't work.<br>\n",
    "    #TODO: Change to \"not more than previous round\"\n",
    "* return information about objective prioritisation for each returned nondom policy and nondom robust policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def ideaMordm(options, split_into = 2, max_depth = 2):\n",
    "    for option in options:\n",
    "        if len(option) == max_depth:\n",
    "            print(\"max depth reached\", option)\n",
    "        else:\n",
    "            for n in range(split_into):\n",
    "                new_option = [option + [n], option + [n]]\n",
    "                print(new_option)\n",
    "                ideaMordm(new_option,split_into,max_depth)\n",
    "    global a\n",
    "    a = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [0, 0]]\n",
      "max depth reached [0, 0]\n",
      "max depth reached [0, 0]\n",
      "[[0, 1], [0, 1]]\n",
      "max depth reached [0, 1]\n",
      "max depth reached [0, 1]\n"
     ]
    }
   ],
   "source": [
    "ideaMordm([[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Iterative (better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 n0\n",
      "__end_period: 0\n",
      "1 n0n1\n",
      "1 n0n2\n",
      "__end_period: 1\n",
      "2 n0n1n3\n",
      "2 n0n1n4\n",
      "2 n0n2n5\n",
      "2 n0n2n6\n",
      "__end_period: 2\n"
     ]
    }
   ],
   "source": [
    "periods = 3\n",
    "nodes = {\"p{}\".format(p): [] if p !=0 else [\"n{}\".format(p)] for p in range(periods)}\n",
    "\n",
    "node_counter = 0\n",
    "\n",
    "for p in range(periods):\n",
    "    for ni, n in enumerate(nodes[\"p{}\".format(p)]):\n",
    "        print(p,n)\n",
    "        if p+2 <= periods:\n",
    "            # in func\n",
    "            node_counter +=1\n",
    "            nodes[\"p{}\".format(p+1)].append(n+\"n{}\".format(node_counter))\n",
    "            #\n",
    "            node_counter +=1\n",
    "            nodes[\"p{}\".format(p+1)].append(n+\"n{}\".format(node_counter))\n",
    "\n",
    "    print(\"__end_period:\",p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for p in range(periods):\n",
    "    all_nodes.append(nodes[\"p{}\".format(p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "4\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "for p in all_nodes:\n",
    "    print(len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Standard imports & printing versions\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Own Model import\n",
    "from lib.fl_model_v5 import *\n",
    "# import lib.fl_model_v5 as flm\n",
    "\n",
    "# for natural sorting\n",
    "import re\n",
    "\n",
    "#for nondominated sorting\n",
    "import lib.pareto as pareto\n",
    "from lib.list_imports import find_loaded_modules\n",
    "\n",
    "# for parallel plotting\n",
    "from lib.parallel_plotting import plot_optimal\n",
    "\n",
    "# For checking ema running time\n",
    "import time\n",
    "\n",
    "import ema_workbench as ema\n",
    "from ema_workbench.em_framework import (Policy, IntegerParameter, Constant,\n",
    "                                        RealParameter, ScalarOutcome,\n",
    "                                        perform_experiments, Model)\n",
    "from ema_workbench import ema_logging\n",
    "# from ema_workbench.em_framework.\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load https://gist.github.com/TRomijn/d9d28ba7b7d5eeac1deea5a26dd326b2/raw/loaded_modules.py\n",
    "\n",
    "'''\n",
    "original author: kinverarity1\n",
    "\n",
    "List loaded modules and packages, and show their version numbers\n",
    "and/or Git repository's HEAD commit SHA.\n",
    "\n",
    "\n",
    "Changes:\n",
    "Minor changes to make compatible with Python 3\n",
    "'''\n",
    "# Standard library modules\n",
    "import types\n",
    "import os\n",
    "\n",
    "# Third-party packages\n",
    "import git      # GitPython\n",
    "\n",
    "\n",
    "def module_path(mod):\n",
    "    '''Returns path to the file that module *mod* comes from.\n",
    "    If it doesn't come from a file, return None.'''\n",
    "    if hasattr(mod, '__file__'):\n",
    "        return os.path.abspath(os.path.dirname(mod.__file__))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "def from_git_repo(mod):\n",
    "    '''Does the module *mod* reside in a Git repository?'''\n",
    "    path = module_path(mod)\n",
    "    if path:\n",
    "        try:\n",
    "            repo = git.Repo(path)\n",
    "        except:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def git_path_sha(mod, slice=slice(0, 8, 1)):\n",
    "    '''Return SHA hash for the HEAD commit for the repository\n",
    "    that the module *mod* resides in.'''\n",
    "    repo = git.Repo(module_path(mod))\n",
    "    return repo.git_dir, repo.head.commit.hexsha[:8]\n",
    "\n",
    "\n",
    "def module_version(mod):\n",
    "    '''Return version string for module *mod*, or nothing if\n",
    "    it doesn't have a \"version\" or \"__version__\" attribute.'''\n",
    "    version = []\n",
    "    if hasattr(mod, '__dict__'):\n",
    "        keys = []\n",
    "        for key in mod.__dict__.keys():\n",
    "            if key.lower() == 'version' or key.lower() == '__version__':\n",
    "                v = mod.__dict__[key]\n",
    "                if isinstance(v, str):\n",
    "                    version.append(v)\n",
    "        if keys:\n",
    "            print (mod, keys)\n",
    "    if version:\n",
    "        return ', '.join(version)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "    \n",
    "def find_loaded_modules(only_versioned_modules=True):\n",
    "    '''Return list of loaded modules for which there is a version\n",
    "    number or a Git repository commit SHA.\n",
    "    \n",
    "    Return a list of *(name, version, path_to_git_repo, git_head_sha)*,\n",
    "    which has an HTML property for pretty display in IPython Notebooks.\n",
    "        \n",
    "    '''\n",
    "    def list_of_lists_to_HTML(lists, header_row=None):\n",
    "        '''Convert a list of a list of strings to a HTML table.'''\n",
    "        s = '<table>'\n",
    "        if header_row:\n",
    "            s += '\\n\\t<tr>\\n\\t\\t'\n",
    "            s += ''.join(['<th>%s</th>' % item for item in header_row])\n",
    "            s += '\\n\\t</tr>'\n",
    "        for inner_list in lists:\n",
    "            s += '\\n\\t<tr>\\n\\t\\t'\n",
    "            s += ''.join(['<td>%s</td>' % item for item in inner_list])\n",
    "            s += '\\n\\t</tr>'\n",
    "        s += '\\n</table>'\n",
    "        return s\n",
    "    \n",
    "    class LoadedModules(list):\n",
    "        '''Very simple wrapper for a list of lists of strings, with an attribute\n",
    "        for display in IPython Notebooks.'''\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            list.__init__(self, *args, **kwargs)\n",
    "            \n",
    "        @property\n",
    "        def HTML(self):\n",
    "            from IPython.display import HTML\n",
    "            return HTML(\n",
    "                    list_of_lists_to_HTML(\n",
    "                            self, header_row=['Name', 'Version', 'Path', 'SHA']))\n",
    "                    \n",
    "    objs = LoadedModules()\n",
    "    for i, mod in enumerate(globals().values()):\n",
    "        if isinstance(mod, types.ModuleType):\n",
    "            if hasattr(mod, '__name__'):\n",
    "                name = mod.__name__\n",
    "            else:\n",
    "                name = ''\n",
    "            \n",
    "            if from_git_repo(mod):\n",
    "                path, sha = git_path_sha(mod)\n",
    "            else:\n",
    "                path = ''\n",
    "                sha = ''\n",
    "            \n",
    "            version = module_version(mod)\n",
    "            \n",
    "            if only_versioned_modules:\n",
    "                flag = version or (path and sha)\n",
    "            else:\n",
    "                flag = True\n",
    "            \n",
    "            if flag:\n",
    "                objs.append([mod.__name__, version, path, sha])\n",
    "    objs.sort(key=lambda r: r[0])\n",
    "    return objs\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "\t<tr>\n",
       "\t\t<th>Name</th><th>Version</th><th>Path</th><th>SHA</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>ema_workbench</td><td>1.1.3</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>git</td><td>2.1.9</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>lib.pareto</td><td>1.1.1-3</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>numpy</td><td>1.14.2</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>pandas</td><td>0.22.0</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>re</td><td>2.2.1</td><td></td><td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>sys</td><td>3.6.4 |Anaconda, Inc.| (default, Mar 12 2018, 20:20:50) [MSC v.1900 64 bit (AMD64)]</td><td></td><td></td>\n",
       "\t</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_loaded_modules().HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is preliminary data. TODO: Find reliable input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Population</th>\n",
       "      <th>Latitude (DD)</th>\n",
       "      <th>Longitude (DD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>743300</td>\n",
       "      <td>27.71</td>\n",
       "      <td>85.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biratnagar</td>\n",
       "      <td>178000</td>\n",
       "      <td>26.46</td>\n",
       "      <td>87.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City  Population  Latitude (DD)  Longitude (DD)\n",
       "0   Kathmandu      743300          27.71           85.31\n",
       "1  Biratnagar      178000          26.46           87.28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DPs from Nepal Data\n",
    "DPs = pd.read_csv(\"Data/Nepal Cities Population.csv\", usecols=[1,2,3,4])\n",
    "\n",
    "# Take only larger cities, because of many null values under 50000 inhabitants. \n",
    "# TODO find better dataset with population and coordinates\n",
    "DPs = DPs [DPs.Population >= 50000]\n",
    "DPs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport</th>\n",
       "      <th>Latitude (DD)</th>\n",
       "      <th>Longitude (DD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tribhuvan intl</td>\n",
       "      <td>27.7</td>\n",
       "      <td>85.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Airport  Latitude (DD)  Longitude (DD)\n",
       "7  Tribhuvan intl           27.7           85.36"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create SPs from Nepal Data\n",
    "airports = pd.read_csv(\"Data/Nepal Airports.csv\", usecols=[0,5,6])\n",
    "SPs = airports[airports['Airport'] == \"Tribhuvan intl\"]\n",
    "SPs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FLO0</td>\n",
       "      <td>28.930736</td>\n",
       "      <td>80.320410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLO1</td>\n",
       "      <td>28.685691</td>\n",
       "      <td>87.105895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name        Lat        Lon\n",
       "0  FLO0  28.930736  80.320410\n",
       "1  FLO1  28.685691  87.105895"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random FLs in Nepal\n",
    "long = np.random.uniform(DPs['Longitude (DD)'].min(),\n",
    "                         DPs['Longitude (DD)'].max(), 20)\n",
    "lat = np.random.uniform(DPs['Latitude (DD)'].min(), DPs['Latitude (DD)'].max(),\n",
    "                        20)\n",
    "FLs = pd.DataFrame([lat, long], index=['Lat', 'Lon']).T\n",
    "FLs['Name'] = ['FLO{}'.format(i) for i in range(FLs.shape[0])]\n",
    "FLs = FLs[['Name', 'Lat', 'Lon']]\n",
    "FLs.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global: Fixed certain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates\n",
    "# all large cities to demand points\n",
    "DPY = {\"DPY{}\".format(i): y for i,y in enumerate(DPs['Latitude (DD)'])}\n",
    "DPX = {\"DPX{}\".format(i): x for i,x in enumerate(DPs['Longitude (DD)'])}\n",
    "\n",
    "# all international airports to supply points:\n",
    "SPY = {\"SPY{}\".format(i): y for i,y in enumerate(SPs['Latitude (DD)'])}\n",
    "SPX = {\"SPX{}\".format(i): x for i,x in enumerate(SPs['Longitude (DD)'])}\n",
    "\n",
    "# Facility locations\n",
    "FLX = {\"FLX{}\".format(i): x for i,x in enumerate(FLs['Lon'])}\n",
    "FLY = {\"FLY{}\".format(i): y for i,y in enumerate(FLs['Lat'])}\n",
    "\n",
    "# Population demand points\n",
    "DPpop = {\"DPpop{}\".format(i): pop for i,pop in enumerate(DPs['Population'])}\n",
    "# DPpop = {\"DPpop{}\".format(i): random.uniform(10,100) for i in range(nr_of_DPs)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global: Fixed uncertain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_fixed_unc = pd.read_csv(\"Data/uncertainties/fixed_uncertainties.csv\").set_index('var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower</th>\n",
       "      <th>best_estimate</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unit_opening_costs</th>\n",
       "      <td>50.0</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit_transport_cost</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL_operations_cost</th>\n",
       "      <td>20.0</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL_range</th>\n",
       "      <td>30.0</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lorry_speed</th>\n",
       "      <td>30.0</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lower  best_estimate  upper\n",
       "var                                             \n",
       "unit_opening_costs    50.0            100    200\n",
       "unit_transport_cost    0.5              1      2\n",
       "FL_operations_cost    20.0             30     50\n",
       "FL_range              30.0             50    150\n",
       "lorry_speed           30.0             40     60"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_fixed_unc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_fixed_unc.loc[\"FL_range\",\"best_estimate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Uncertain Data: generate random for now:\n",
    "DFs becomes a global. can be accessed by using its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSR = Disruption\n",
    "DSRDP = {\"DSRDP{}\".format(i): random.uniform (1, 2) for i in range(len(DPX))}\n",
    "DSRFL = {\"DSRFL{}\".format(i): random.uniform (1, 2) for i in range(len(FLX))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label each branch. start with:\n",
    "start_label = \"t0b0\"\n",
    "# Each branch has a separate perception of what the data is.\n",
    "# A dictionary can keep track of data for each branch, linked via label\n",
    "global_dfs_var_unc_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dfs_var_unc_data [start_label] = pd.DataFrame.from_dict({**DSRDP, **DSRFL}, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DSRDP0</th>\n",
       "      <td>1.0531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "DSRDP0  1.0531"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_dfs_var_unc_data [start_label].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>best_estimate</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DSRDP0</th>\n",
       "      <td>1.0531</td>\n",
       "      <td>1.048258</td>\n",
       "      <td>1.742403</td>\n",
       "      <td>1.39533</td>\n",
       "      <td>0.34223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual     lower     upper  best_estimate  difference\n",
       "DSRDP0  1.0531  1.048258  1.742403        1.39533     0.34223"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create upper and lower bound\n",
    "global_dfs_var_unc_data[start_label] = global_dfs_var_unc_data[\n",
    "    start_label].rename(columns={0: \"actual\"})\n",
    "global_dfs_var_unc_data[start_label]['lower'] = (\n",
    "    global_dfs_var_unc_data[start_label]['actual'] - 1\n",
    ") * np.random.uniform(size=global_dfs_var_unc_data[start_label].shape[0]) + 1\n",
    "global_dfs_var_unc_data[start_label]['upper'] = (\n",
    "    2 - global_dfs_var_unc_data[start_label]['actual']) * np.random.uniform(\n",
    "        size=global_dfs_var_unc_data[start_label]\n",
    "        .shape[0]) + global_dfs_var_unc_data[start_label]['actual']\n",
    "global_dfs_var_unc_data[start_label]['best_estimate'] = (\n",
    "    global_dfs_var_unc_data[start_label]['upper'] +\n",
    "    global_dfs_var_unc_data[start_label]['lower']) / 2\n",
    "global_dfs_var_unc_data[start_label][\n",
    "    'difference'] = global_dfs_var_unc_data[start_label]['best_estimate'] - global_dfs_var_unc_data[start_label]['actual']\n",
    "global_dfs_var_unc_data[start_label].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['t0b0'])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_dfs_var_unc_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Globals:\n",
    "- Create Starting situation policies:\n",
    "- List of all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_situation = {key:0 for key in FLs.Name}\n",
    "global_models = {}\n",
    "# global_period_counter = 0 # period is not global\n",
    "global_node_counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def create_policies(FL_dict, print_pols=False):\n",
    "    \"\"\"\n",
    "    Takes the current network of Facility Locations and returns all possible policies for one added FL.\n",
    "    \n",
    "    Input: current option (Dict of FLs)\n",
    "    Output: List of options (Dicts of FLs)\n",
    "    \n",
    "    Printing module not completely reliable. doesnt print whats actually in thereTODO\n",
    "    \"\"\"\n",
    "    def natural_key(string_):\n",
    "        return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]\n",
    "    \n",
    "    # All FL names\n",
    "    FL_keys = sorted(FL_dict.keys(),key=natural_key)\n",
    "    # All FL values indicating whether operational\n",
    "    FL_values = [FL_dict[key] for key in FL_keys]\n",
    "    \n",
    "    i_operational_fls = i_FL_op = [i for i,x in enumerate(FL_values) if x == 1]\n",
    "    \n",
    "    # Create list of policies  \n",
    "    pols = np.identity(len(FL_keys))\n",
    "    # Set already operational facilities to operational\n",
    "    pols[:,i_operational_fls] = 1\n",
    "    \n",
    "    #Delete policies where no new FLs are placed \n",
    "    new_n_operational_fls = sum(FL_values) + 1\n",
    "    pols = pols[pols.sum(axis = 1) == new_n_operational_fls]\n",
    "\n",
    "    \n",
    "    # Return a list of dictionaries\n",
    "    policy_list = []\n",
    "    for pol in pols:\n",
    "        policy_list.append({key:value for key,value in zip(FL_keys,pol)})\n",
    "    \n",
    "    if print_pols == True:\n",
    "        print(\"total policies:\",len(policy_list))\n",
    "        for n,i in enumerate(policy_list):\n",
    "            for v in i.values():\n",
    "                print (int(v), end='')\n",
    "            print(\" <- policy {}\".format(n))\n",
    "                \n",
    "    return policy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_signalNoise(data, obj):\n",
    "    '''\n",
    "    data : 1d array, the values of an outcome indicator for a policy\n",
    "    obj  : the objective corresponding to an outcome indicator, 1 or -1\n",
    "    '''\n",
    "    if obj == -1: #MINIMIZE\n",
    "        score = (np.mean(data)+1)*(np.std(data)+1) #to avoid division by zero if the std. deviation is zero, we can add 1.\n",
    "    elif obj == 1: #MAXIMIZE\n",
    "        score = (np.mean(data)+1)/(np.std(data)+1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_maxregret(data, obj):\n",
    "    '''\n",
    "    data : a list of 1d arrays whose shape is no_policies x no_scenarios\n",
    "    obj : -1 or 1, the objective \n",
    "    '''\n",
    "    data = np.array(data)\n",
    "    if obj == 1: #MAXIMIZE \n",
    "        #find the best case in each scenario, therefore use the max function of numpy on the axis of policies\n",
    "        zero_regrets = np.max(data, axis=0)\n",
    "    elif obj == -1: #MINIMIZE\n",
    "        zero_regrets = np.min(data, axis=0)\n",
    "    \n",
    "    #determine the regret values for eaxh policy in each scenario\n",
    "    regrets = [abs(np.subtract(data[p], zero_regrets)) for p in range(data.shape[0])]\n",
    "    \n",
    "    max_regrets = np.max(regrets, axis=1)\n",
    "    \n",
    "    return max_regrets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "code_folding": [
     14,
     19
    ]
   },
   "outputs": [],
   "source": [
    "EMA_model_dict = {}  # XX somewhere else: global\n",
    "\n",
    "\n",
    "def MORDM(\n",
    "        current=None,\n",
    "        current_period=None,\n",
    "        trace_label=None,\n",
    "        # fixed_data=None,\n",
    "        # var_data=None,\n",
    "        n_scenarios=100,\n",
    "        additional_info=None,\n",
    "        show_MORDM_graphics=False,\n",
    "        show_model_graphics=False):\n",
    "    \"\"\"\n",
    "    current: indexes of current operational locations\n",
    "    trace_label: label of input node\n",
    "    fixed_data: \n",
    "    var_data: df of variable data for each \n",
    "    max_depth: maximum number of total FLS\n",
    "    \"\"\"\n",
    "    #     if sum(current.values()) >= max_depth:\n",
    "    #         raise NotImplementedError(\n",
    "    #             \"Everything might go right(no error). This function is not well implemented. Change to > instead of >=\"\n",
    "    #         )\n",
    "\n",
    "    if show_MORDM_graphics == True:\n",
    "        raise NotImplementedError(\"\"\"visualisations are not implemented yet. \n",
    "            Not sure yet if impementing graphics in MPMORDM is usefull for every period \"\"\"\n",
    "                                  )\n",
    "\n",
    "    #Start Many Objective Optimisation\n",
    "    #best estimate values\n",
    "    best_estimate_disruptions = {\n",
    "        i: be\n",
    "        for be, i in zip(global_dfs_var_unc_data[trace_label]['best_estimate'],\n",
    "                         global_dfs_var_unc_data[trace_label].index)\n",
    "    }\n",
    "\n",
    "    optional_policies = create_policies(current, print_pols=False)\n",
    "\n",
    "    #evaluate all policies\n",
    "    best_est_results_opt_pols = []\n",
    "    for policy in optional_policies:\n",
    "        best_est_results_opt_pols.append(\n",
    "            FL_model(\n",
    "                unit_opening_costs=global_fixed_unc.loc[\"unit_opening_costs\",\n",
    "                                                        \"best_estimate\"],\n",
    "                unit_transport_cost=global_fixed_unc.loc[\"unit_transport_cost\",\n",
    "                                                         \"best_estimate\"],\n",
    "                FL_operations_cost=global_fixed_unc.loc[\"FL_operations_cost\",\n",
    "                                                        \"best_estimate\"],\n",
    "                graphical_representation=show_model_graphics,\n",
    "                FL_range=global_fixed_unc.loc[\"FL_range\",\n",
    "                                              \"best_estimate\"],  # km? --> m\n",
    "                dist_method=\"great_circle\",\n",
    "                lorry_speed=global_fixed_unc.loc[\n",
    "                    \"lorry_speed\", \"best_estimate\"],  #km/u? --> m/s\n",
    "                # fixed certain\n",
    "                **SPX,\n",
    "                **SPY,\n",
    "                **DPX,\n",
    "                **DPY,\n",
    "                **FLX,\n",
    "                **FLY,\n",
    "                **DPpop,\n",
    "                # specific\n",
    "                **policy,\n",
    "                **best_estimate_disruptions))\n",
    "\n",
    "    # outcome indicators, as internally used by the model\n",
    "    oois = [\n",
    "        'total_costs', 'nr_uncovered_DPs', 'total_uncovered_demand',\n",
    "        'max_distr_time'\n",
    "    ]\n",
    "    # Put outcomes in DF\n",
    "    df_best_est_results_opt_pols = pd.DataFrame(\n",
    "        np.asarray(best_est_results_opt_pols)[:, :4], columns=oois)\n",
    "\n",
    "    #nondominated sorting\n",
    "    nondominated_BE_policy_results = np.array(\n",
    "        pareto.eps_sort(\n",
    "            [list(df_best_est_results_opt_pols.itertuples(index=True))],\n",
    "            [1, 2, 3, 4], [1e-9, 1e-9, 1e-9, 1e-9]))\n",
    "\n",
    "    #Filter out those where new demand is covered\n",
    "    #TODO: Works only first time. After that doesn't work.\n",
    "    #TODO: Change to \"not more than previous round\"\n",
    "    nondominated_BE_policy_results = nondominated_BE_policy_results[\n",
    "        nondominated_BE_policy_results[:, 4] != 0]\n",
    "\n",
    "    #put nondominated policies in array\n",
    "    nondom_i = [int(a[0]) for a in nondominated_BE_policy_results]\n",
    "    nondominated_BE_policies = np.array(optional_policies)[nondom_i]\n",
    "\n",
    "    df_nondom_BE_pols = pd.DataFrame(\n",
    "        nondominated_BE_policy_results, columns=[\"i\"] + oois).set_index(\"i\")\n",
    "    df_nondom_BE_pols.to_csv(\n",
    "        \"results/mpmordm/nondom_BE_pols{}.csv\".format(trace_label))\n",
    "\n",
    "\n",
    "    #End Many Objective Optimisation\n",
    "    #Start Robustness analysis\n",
    "\n",
    "    EMA_model_dict[trace_label] = Model(\"flmodel{}\".format(trace_label),\n",
    "                                        FL_model)\n",
    "\n",
    "    EMA_model_dict[trace_label].locations = [\n",
    "        Constant(\"DPX{}\".format(i), x)\n",
    "        for i, x in zip(DPs.index, DPs['Longitude (DD)'])\n",
    "    ] + [\n",
    "        Constant(\"DPY{}\".format(i), y)\n",
    "        for i, y in zip(DPs.index, DPs['Latitude (DD)'])\n",
    "    ] + [\n",
    "        Constant(\"SPX{}\".format(i), x)\n",
    "        for i, x in zip(SPs.index, SPs['Longitude (DD)'])\n",
    "    ] + [\n",
    "        Constant(\"SPY{}\".format(i), y)\n",
    "        for i, y in zip(SPs.index, SPs['Latitude (DD)'])\n",
    "    ] + [\n",
    "        Constant(\"FLX{}\".format(i), x) for i, x in zip(FLs.index, FLs['Lon'])\n",
    "    ] + [\n",
    "        Constant(\"FLY{}\".format(i), y) for i, y in zip(FLs.index, FLs['Lat'])\n",
    "    ]\n",
    "\n",
    "    # model.locations_uncertain =   [\n",
    "    #     RealParameter(\"FLX{}\".format(i), DPs['Longitude (DD)'].min(), DPs['Longitude (DD)'].max()) for i in range(nr_of_FLs)\n",
    "    # ] + [RealParameter(\"FLY{}\".format(i), DPs['Latitude (DD)'].min(), DPs['Latitude (DD)'].max()) for i in range(nr_of_FLs)]\n",
    "\n",
    "    EMA_model_dict[trace_label].constants = [\n",
    "        Constant('graphical_representation', False),\n",
    "        Constant('dist_method', 'great_circle'),\n",
    "        Constant('Error_Test', 1),  # this doesn't do anything. \n",
    "        #list of other constants\n",
    "        #     Constant\n",
    "    ] + EMA_model_dict[trace_label].locations + [  # population DPs\n",
    "        Constant(\"DPpop{}\".format(i), pop)\n",
    "        for i, pop in zip(DPs.index, DPs['Population'])\n",
    "    ]\n",
    "\n",
    "    # Reachability of Demand Points and Facility Locations can be disrupted\n",
    "    # Disruption also determines demand (disr-1)*pop\n",
    "    EMA_model_dict[trace_label].disruptions = [\n",
    "        RealParameter(i, l, u) for i, l, u in zip(global_dfs_var_unc_data[\n",
    "            trace_label].index, global_dfs_var_unc_data[trace_label][\n",
    "                'lower'], global_dfs_var_unc_data[trace_label]['upper'])\n",
    "    ]\n",
    "\n",
    "    EMA_model_dict[trace_label].uncertainties = [\n",
    "        RealParameter(i, l, u)\n",
    "        for i, l, u in zip(global_fixed_unc.index, global_fixed_unc.lower,\n",
    "                           global_fixed_unc.upper)\n",
    "    ] + EMA_model_dict[trace_label].disruptions  #+ model.locations_uncertain\n",
    "\n",
    "    EMA_model_dict[trace_label].outcomes = [\n",
    "        ScalarOutcome(\"total_costs\", kind=ScalarOutcome.MINIMIZE),\n",
    "        ScalarOutcome(\"nr_uncovered_DPs\", kind=ScalarOutcome.MINIMIZE),\n",
    "        ScalarOutcome(\"total_uncovered_demand\", kind=ScalarOutcome.MINIMIZE),\n",
    "        ScalarOutcome(\n",
    "            \"max_distr_time\",\n",
    "            kind=ScalarOutcome.MINIMIZE,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    if [o.name for o in EMA_model_dict[trace_label].outcomes] != oois:\n",
    "        print(\"Watch out! Oois and model outcome names are not similar!\")\n",
    "\n",
    "    nondominated_BE_policies_EMA = []\n",
    "    for name, pol in zip(nondom_i, nondominated_BE_policies):\n",
    "        nondominated_BE_policies_EMA.append(Policy(\"{}\".format(name), **pol))\n",
    "\n",
    "    time1 = time.time()\n",
    "    all_scen_results_nondom_pols = perform_experiments(\n",
    "        EMA_model_dict[trace_label], n_scenarios, nondominated_BE_policies_EMA)\n",
    "    time2 = time.time()\n",
    "    print(\"Total time:{}\".format(time2 - time1), \"\\n\",\n",
    "          \"time per run = {}\".format(\n",
    "              (time2 - time1) /\n",
    "              (n_scenarios * len(nondominated_BE_policies_EMA))))\n",
    "\n",
    "    ema.save_results(all_scen_results_nondom_pols,\n",
    "                     \"results/mpmordm/{}.tar.gz\".format(trace_label))\n",
    "    experiments, outcomes = all_scen_results_nondom_pols\n",
    "\n",
    "    sigN_results = []\n",
    "\n",
    "    for policy in nondominated_BE_policies_EMA:\n",
    "        #filter the outcome values corresponding to each policy using a logical index\n",
    "        logical_index = experiments['policy'] == policy.name\n",
    "        # If ever something goes wrong here, probably add: int() to policy.name\n",
    "        pol_outcomes = {\n",
    "            key: outcomes[key][logical_index]\n",
    "            for key in outcomes.keys()\n",
    "        }\n",
    "        temp_result = {}\n",
    "        for ooi in EMA_model_dict[trace_label].outcomes:\n",
    "            temp_result[ooi.name] = calculate_signalNoise(\n",
    "                pol_outcomes[ooi.name], ooi.kind)\n",
    "        sigN_results.append(temp_result)\n",
    "\n",
    "    df_sigN = pd.DataFrame(\n",
    "        sigN_results, index=[pol.name for pol in nondominated_BE_policies_EMA])\n",
    "\n",
    "    reg_results = {}\n",
    "    # we need to iterate over the outcomes differently now,\n",
    "    #because the maximum egret calculation requires the outcome values for all policies\n",
    "    for ooi in EMA_model_dict[trace_label].outcomes:\n",
    "        data = []\n",
    "        for policy in nondominated_BE_policies_EMA:\n",
    "            logical_index = experiments['policy'] == policy.name\n",
    "            # If ever something goes wrong here, add int() to policy.name\n",
    "            data.append(outcomes[ooi.name][logical_index])\n",
    "        reg_results[ooi.name] = calculate_maxregret(data, ooi.kind)\n",
    "    df_regret = pd.DataFrame.from_dict(\n",
    "        reg_results,\n",
    "        orient='columns',\n",
    "    )\n",
    "    df_regret.index = [pol.name for pol in nondominated_BE_policies_EMA]\n",
    "\n",
    "    all_robustness_scores = pd.merge(\n",
    "        df_regret,\n",
    "        df_sigN,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        suffixes=(\"_regret\", \"_sigN\"))\n",
    "\n",
    "    robust_nondominated_policies = pareto.eps_sort(\n",
    "        [list(all_robustness_scores.itertuples(index=True))],\n",
    "        [i + 1 for i in range(all_robustness_scores.shape[1])],\n",
    "        [1e-9] * all_robustness_scores.shape[1])\n",
    "\n",
    "    if len(robust_nondominated_policies) == 0:\n",
    "        print(\"something went wrong\")\n",
    "    elif len(robust_nondominated_policies) == 1:\n",
    "        print(\"no branching, only a single nondominated robust location\")\n",
    "        temp_cols = [\"pol_i\"] + list(all_robustness_scores.columns)\n",
    "\n",
    "        df_rob_nondom_pols = pd.DataFrame(\n",
    "            robust_nondominated_policies, columns=temp_cols).set_index(\"pol_i\")\n",
    "    #     print(robust_nondominated_policies)\n",
    "    else:\n",
    "        temp_cols = [\"pol_i\"] + list(all_robustness_scores.columns)\n",
    "        df_rob_nondom_pols = pd.DataFrame(\n",
    "            robust_nondominated_policies, columns=temp_cols).set_index(\"pol_i\")\n",
    "\n",
    "    df_rob_nondom_pols.to_csv(\n",
    "        \"results/mpmordm/nondom_rob_pols{}.csv\".format(trace_label))\n",
    "\n",
    "    #     return df_rob_nondom_pols\n",
    "    return df_rob_nondom_pols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing single cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: save csv nondom pols + csv rob nondom pols\n",
    "possible: clear op variable space with del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 10 scenarios * 3 policies * 1 model(s) = 30 experiments\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 3 cases completed\n",
      "[MainProcess/INFO] 6 cases completed\n",
      "[MainProcess/INFO] 9 cases completed\n",
      "[MainProcess/INFO] 12 cases completed\n",
      "[MainProcess/INFO] 15 cases completed\n",
      "[MainProcess/INFO] 18 cases completed\n",
      "[MainProcess/INFO] 21 cases completed\n",
      "[MainProcess/INFO] 24 cases completed\n",
      "[MainProcess/INFO] 27 cases completed\n",
      "[MainProcess/INFO] 30 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to C:\\Users\\timro\\Dropbox\\MSc EPA\\0 Master Thesis\\Python Files\\Thesis\\Facility Location Model\\results\\mpmordm\\t0b0.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:1.3652184009552002 \n",
      " time per run = 0.04550728003184001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = MORDM(\n",
    "    current=start_situation,n_scenarios=10, trace_label=start_label, show_model_graphics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10', '14', '15']"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_oois = [\n",
    "        'total_costs', 'nr_uncovered_DPs', 'total_uncovered_demand',\n",
    "        'max_distr_time'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+01, 3.30715516e+07, 1.70000000e+01, 3.44687906e+06,\n",
       "        8.51311416e+00],\n",
       "       [1.40000000e+01, 8.46888020e+07, 1.60000000e+01, 3.11658919e+06,\n",
       "        4.99872757e+00],\n",
       "       [1.50000000e+01, 3.71179960e+07, 1.70000000e+01, 3.34935776e+06,\n",
       "        4.76749379e+00]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>total_costs</th>\n",
       "      <th>nr_uncovered_DPs</th>\n",
       "      <th>total_uncovered_demand</th>\n",
       "      <th>max_distr_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.307155e+07</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.446879e+06</td>\n",
       "      <td>8.513114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.468880e+07</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.116589e+06</td>\n",
       "      <td>4.998728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.711800e+07</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.349358e+06</td>\n",
       "      <td>4.767494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      i   total_costs  nr_uncovered_DPs  total_uncovered_demand  \\\n",
       "0  10.0  3.307155e+07              17.0            3.446879e+06   \n",
       "1  14.0  8.468880e+07              16.0            3.116589e+06   \n",
       "2  15.0  3.711800e+07              17.0            3.349358e+06   \n",
       "\n",
       "   max_distr_time  \n",
       "0        8.513114  \n",
       "1        4.998728  \n",
       "2        4.767494  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test, columns=[\"i\"]+test_oois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'total_costs',\n",
       " 'nr_uncovered_DPs',\n",
       " 'total_uncovered_demand',\n",
       " 'max_distr_time']"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regret, df_sigN = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_distr_time_regret</th>\n",
       "      <th>nr_uncovered_DPs_regret</th>\n",
       "      <th>total_costs_regret</th>\n",
       "      <th>total_uncovered_demand_regret</th>\n",
       "      <th>max_distr_time_sigN</th>\n",
       "      <th>nr_uncovered_DPs_sigN</th>\n",
       "      <th>total_costs_sigN</th>\n",
       "      <th>total_uncovered_demand_sigN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.136028</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.325350e+08</td>\n",
       "      <td>1.754780e+06</td>\n",
       "      <td>43.951163</td>\n",
       "      <td>45.503851</td>\n",
       "      <td>1.255424e+16</td>\n",
       "      <td>1.334358e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.288236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.566187e+08</td>\n",
       "      <td>2.135245e+05</td>\n",
       "      <td>22.475893</td>\n",
       "      <td>69.488899</td>\n",
       "      <td>3.889449e+16</td>\n",
       "      <td>2.535527e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.603670</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.825804e+08</td>\n",
       "      <td>3.008082e+05</td>\n",
       "      <td>21.690812</td>\n",
       "      <td>62.696264</td>\n",
       "      <td>3.833043e+16</td>\n",
       "      <td>2.541758e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_distr_time_regret  nr_uncovered_DPs_regret  total_costs_regret  \\\n",
       "10               5.136028                      6.0        1.325350e+08   \n",
       "14               0.288236                      1.0        3.566187e+08   \n",
       "15               4.603670                      2.0        3.825804e+08   \n",
       "\n",
       "    total_uncovered_demand_regret  max_distr_time_sigN  nr_uncovered_DPs_sigN  \\\n",
       "10                   1.754780e+06            43.951163              45.503851   \n",
       "14                   2.135245e+05            22.475893              69.488899   \n",
       "15                   3.008082e+05            21.690812              62.696264   \n",
       "\n",
       "    total_costs_sigN  total_uncovered_demand_sigN  \n",
       "10      1.255424e+16                 1.334358e+12  \n",
       "14      3.889449e+16                 2.535527e+12  \n",
       "15      3.833043e+16                 2.541758e+12  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_regret,df_sigN, left_index=True, right_index=True, suffixes=(\"_regret\",\"_sigN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMA_model_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MORDM_cycle(current, last, trace_label, fixed_data, var_data, max_depth = 2, additional_info=None):\n",
    "    \"\"\"\n",
    "    MORDM_cycle with micromodel. Micromodel changes factors/information based on the last decision\n",
    "    \n",
    "    \"\"\"\n",
    "    if trace_label != max_depth:\n",
    "        raise NotImplementedError (\"stop if max depth is reached\")\n",
    "    # micromodel here\n",
    "    #Based on current / last\n",
    "    \n",
    "    \n",
    "    MORDM(current, trace_label, fixed_data, var_data, max_depth = max_depth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
